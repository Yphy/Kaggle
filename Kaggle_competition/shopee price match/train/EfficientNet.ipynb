{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "foster-arbor",
   "metadata": {},
   "source": [
    "### 참고 커널\n",
    "* Eff, nfnet Training\n",
    "    https://www.kaggle.com/parthdhameliya77/shopee-pytorch-eca-nfnet-l0-image-training\n",
    "\n",
    "* ArcFace + CV\n",
    "    https://www.kaggle.com/underwearfitting/pytorch-densenet-arcface-validation-training\n",
    "\n",
    "* EffB5 Inference\n",
    "    https://www.kaggle.com/parthdhameliya77/pytorch-efficientnet-b5-image-tfidf-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gothic-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "data_path = '/mnt/hdd1/wearly/kaggle/shopee/'\n",
    "sys.path.append(data_path+'pytorch-image-models-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "historical-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os \n",
    "import cv2 \n",
    "import timm\n",
    "import neptune\n",
    "\n",
    "import albumentations \n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch \n",
    "import torch.nn.functional as F \n",
    "from torch import nn \n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "import math\n",
    "\n",
    "from tqdm.notebook import tqdm \n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extensive-suggestion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/younghoon/shopee/e/SHOPEE-52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Experiment(SHOPEE-52)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neptune.init(project_qualified_name = 'younghoon/shopee',\n",
    "              api_token = 'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiZjEwMWE3NDUtZDFhZS00MDYxLWFkNjktODgzN2RiNWEwNmY1In0=',\n",
    "              )\n",
    "#pass parameters to create experiment\n",
    "neptune.create_experiment(params=  None , name= 'efficientnet_b5_ns', description = 'batch:8, lr_max:32, 40epochs,mish+ranger'\n",
    "                          , tags=['efficientnet_b5_ns_original'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-council",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elementary-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \n",
    "    DATA_DIR = '/mnt/hdd1/wearly/kaggle/shopee/train_images/'\n",
    "    TRAIN_CSV = '/mnt/hdd1/wearly/kaggle/shopee/train.csv'\n",
    "\n",
    "    IMG_SIZE = 512\n",
    "    MEAN = [0.485, 0.456, 0.406] #Imagenet normalization\n",
    "    STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "    EPOCHS = 40  # Try 15 epochs\n",
    "    BATCH_SIZE = 8\n",
    "\n",
    "    NUM_WORKERS = 4\n",
    "    DEVICE = 'cuda'\n",
    "\n",
    "    CLASSES = 11014 \n",
    "    SCALE = 30 \n",
    "    MARGIN = 0.5 #이것도 높이는 시도, 낮을수록 빠르다고함 높을수록 beneficial\n",
    "\n",
    "    MODEL_NAME = 'tf_efficientnet_b5_ns' #eca_nfnet_l0\n",
    "    FC_DIM = 512\n",
    "    SCHEDULER_PARAMS = {\n",
    "            \"lr_start\": 1e-5,\n",
    "            \"lr_max\": 1e-5 * BATCH_SIZE, #배치에 따라서 안곱해주는지?체크해봐야함\n",
    "            \"lr_min\": 1e-6,\n",
    "            \"lr_ramp_ep\": 5,\n",
    "            \"lr_sus_ep\": 0,\n",
    "            \"lr_decay\": 0.8,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-verification",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "complex-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,df, transform = None):\n",
    "        self.df = df \n",
    "        self.root_dir = Config.DATA_DIR\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img_path = os.path.join(self.root_dir,row.image)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = row.label_group\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return {\n",
    "            'image' : image,\n",
    "            'label' : torch.tensor(label).long()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-creation",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "secondary-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return albumentations.Compose(\n",
    "        [   \n",
    "            albumentations.Resize(Config.IMG_SIZE,Config.IMG_SIZE,always_apply=True),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.Rotate(limit=120, p=0.8),\n",
    "            albumentations.RandomBrightness(limit=(0.09, 0.6), p=0.5),\n",
    "            albumentations.Normalize(mean = Config.MEAN, std = Config.STD),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-apparel",
   "metadata": {},
   "source": [
    "### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "utility-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeScheduler(_LRScheduler):\n",
    "    def __init__(self, optimizer, lr_start=5e-6, lr_max=1e-5,\n",
    "                 lr_min=1e-6, lr_ramp_ep=5, lr_sus_ep=0, lr_decay=0.8,\n",
    "                 last_epoch=-1):\n",
    "        self.lr_start = lr_start\n",
    "        self.lr_max = lr_max\n",
    "        self.lr_min = lr_min\n",
    "        self.lr_ramp_ep = lr_ramp_ep\n",
    "        self.lr_sus_ep = lr_sus_ep\n",
    "        self.lr_decay = lr_decay\n",
    "        super(ShopeeScheduler, self).__init__(optimizer, last_epoch)\n",
    "        \n",
    "    def get_lr(self):\n",
    "        if not self._get_lr_called_within_step:\n",
    "            warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
    "                          \"please use `get_last_lr()`.\", UserWarning)\n",
    "        \n",
    "        if self.last_epoch == 0:\n",
    "            self.last_epoch += 1\n",
    "            return [self.lr_start for _ in self.optimizer.param_groups]\n",
    "        \n",
    "        lr = self._compute_lr_from_epoch()\n",
    "        self.last_epoch += 1\n",
    "        \n",
    "        return [lr for _ in self.optimizer.param_groups]\n",
    "    \n",
    "    def _get_closed_form_lr(self):\n",
    "        return self.base_lrs\n",
    "    \n",
    "    def _compute_lr_from_epoch(self):\n",
    "        if self.last_epoch < self.lr_ramp_ep:\n",
    "            lr = ((self.lr_max - self.lr_start) / \n",
    "                  self.lr_ramp_ep * self.last_epoch + \n",
    "                  self.lr_start)\n",
    "        \n",
    "        elif self.last_epoch < self.lr_ramp_ep + self.lr_sus_ep:\n",
    "            lr = self.lr_max\n",
    "            \n",
    "        else:\n",
    "            lr = ((self.lr_max - self.lr_min) * self.lr_decay**\n",
    "                  (self.last_epoch - self.lr_ramp_ep - self.lr_sus_ep) + \n",
    "                  self.lr_min)\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-chemistry",
   "metadata": {},
   "source": [
    "### centralized_gradient + Ranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "south-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralized_gradient(x, use_gc=True, gc_conv_only=False):\n",
    "    if use_gc:\n",
    "        if gc_conv_only:\n",
    "            if len(list(x.size())) > 3:\n",
    "                x.add_(-x.mean(dim=tuple(range(1, len(list(x.size())))), keepdim=True))\n",
    "        else:\n",
    "            if len(list(x.size())) > 1:\n",
    "                x.add_(-x.mean(dim=tuple(range(1, len(list(x.size())))), keepdim=True))\n",
    "    return x\n",
    "\n",
    "\n",
    "class Ranger(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3,                       # lr\n",
    "                 alpha=0.5, k=5, N_sma_threshhold=5,           # Ranger options\n",
    "                 betas=(.95, 0.999), eps=1e-5, weight_decay=0,  # Adam options\n",
    "                 # Gradient centralization on or off, applied to conv layers only or conv + fc layers\n",
    "                 use_gc=True, gc_conv_only=False, gc_loc=True\n",
    "                 ):\n",
    "\n",
    "        # parameter checks\n",
    "        if not 0.0 <= alpha <= 1.0:\n",
    "            raise ValueError(f'Invalid slow update rate: {alpha}')\n",
    "        if not 1 <= k:\n",
    "            raise ValueError(f'Invalid lookahead steps: {k}')\n",
    "        if not lr > 0:\n",
    "            raise ValueError(f'Invalid Learning Rate: {lr}')\n",
    "        if not eps > 0:\n",
    "            raise ValueError(f'Invalid eps: {eps}')\n",
    "\n",
    "        # parameter comments:\n",
    "        # beta1 (momentum) of .95 seems to work better than .90...\n",
    "        # N_sma_threshold of 5 seems better in testing than 4.\n",
    "        # In both cases, worth testing on your dataset (.90 vs .95, 4 vs 5) to make sure which works best for you.\n",
    "\n",
    "        # prep defaults and init torch.optim base\n",
    "        defaults = dict(lr=lr, alpha=alpha, k=k, step_counter=0, betas=betas,\n",
    "                        N_sma_threshhold=N_sma_threshhold, eps=eps, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "        # adjustable threshold\n",
    "        self.N_sma_threshhold = N_sma_threshhold\n",
    "\n",
    "        # look ahead params\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "\n",
    "        # radam buffer for state\n",
    "        self.radam_buffer = [[None, None, None] for ind in range(10)]\n",
    "\n",
    "        # gc on or off\n",
    "        self.gc_loc = gc_loc\n",
    "        self.use_gc = use_gc\n",
    "        self.gc_conv_only = gc_conv_only\n",
    "        # level of gradient centralization\n",
    "        #self.gc_gradient_threshold = 3 if gc_conv_only else 1\n",
    "\n",
    "        print(\n",
    "            f\"Ranger optimizer loaded. \\nGradient Centralization usage = {self.use_gc}\")\n",
    "        if (self.use_gc and self.gc_conv_only == False):\n",
    "            print(f\"GC applied to both conv and fc layers\")\n",
    "        elif (self.use_gc and self.gc_conv_only == True):\n",
    "            print(f\"GC applied to conv layers only\")\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        print(\"set state called\")\n",
    "        super(Ranger, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        # note - below is commented out b/c I have other work that passes back the loss as a float, and thus not a callable closure.\n",
    "        # Uncomment if you need to use the actual closure...\n",
    "\n",
    "        # if closure is not None:\n",
    "        #loss = closure()\n",
    "\n",
    "        # Evaluate averages and grad, update param tensors\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError(\n",
    "                        'Ranger optimizer does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]  # get state dict for this param\n",
    "\n",
    "                if len(state) == 0:  # if first time to run...init dictionary with our desired entries\n",
    "                    # if self.first_run_check==0:\n",
    "                    # self.first_run_check=1\n",
    "                    #print(\"Initializing slow buffer...should not see this at load from saved model!\")\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "\n",
    "                    # look ahead weight storage now in state dict\n",
    "                    state['slow_buffer'] = torch.empty_like(p.data)\n",
    "                    state['slow_buffer'].copy_(p.data)\n",
    "\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(\n",
    "                        p_data_fp32)\n",
    "\n",
    "                # begin computations\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                # GC operation for Conv layers and FC layers\n",
    "                # if grad.dim() > self.gc_gradient_threshold:\n",
    "                #    grad.add_(-grad.mean(dim=tuple(range(1, grad.dim())), keepdim=True))\n",
    "                if self.gc_loc:\n",
    "                    grad = centralized_gradient(grad, use_gc=self.use_gc, gc_conv_only=self.gc_conv_only)\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                # compute variance mov avg\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n",
    "\n",
    "                # compute mean moving avg\n",
    "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
    "\n",
    "                buffered = self.radam_buffer[int(state['step'] % 10)]\n",
    "\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * \\\n",
    "                        state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "                    if N_sma > self.N_sma_threshhold:\n",
    "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (\n",
    "                            N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                # if group['weight_decay'] != 0:\n",
    "                #    p_data_fp32.add_(-group['weight_decay']\n",
    "                #                     * group['lr'], p_data_fp32)\n",
    "\n",
    "                # apply lr\n",
    "                if N_sma > self.N_sma_threshhold:\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    G_grad = exp_avg / denom\n",
    "                else:\n",
    "                    G_grad = exp_avg\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    G_grad.add_(p_data_fp32, alpha=group['weight_decay'])\n",
    "                # GC operation\n",
    "                if self.gc_loc == False:\n",
    "                    G_grad = centralized_gradient(G_grad, use_gc=self.use_gc, gc_conv_only=self.gc_conv_only)\n",
    "\n",
    "                p_data_fp32.add_(G_grad, alpha=-step_size * group['lr'])\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "                # integrated look ahead...\n",
    "                # we do it at the param level instead of group level\n",
    "                if state['step'] % group['k'] == 0:\n",
    "                    # get access to slow param tensor\n",
    "                    slow_p = state['slow_buffer']\n",
    "                    # (fast weights - slow weights) * alpha\n",
    "                    slow_p.add_(p.data - slow_p, alpha=self.alpha)\n",
    "                    # copy interpolated weights to RAdam param tensor\n",
    "                    p.data.copy_(slow_p)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-terror",
   "metadata": {},
   "source": [
    "### Mish activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "related-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#credit : https://github.com/tyunist/memory_efficient_mish_swish/blob/master/mish.py\n",
    "\n",
    "''' I just wanted to understand and implement custom backward activation in PyTorch so I choose this.\n",
    "    You can also simply use this function below too.\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mish, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input * (torch.tanh(F.softplus(input)))\n",
    "'''\n",
    "\n",
    "class Mish_func(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.tanh(F.softplus(i))\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_tensors[0]\n",
    "  \n",
    "        v = 1. + i.exp()\n",
    "        h = v.log() \n",
    "        grad_gh = 1./h.cosh().pow_(2) \n",
    "\n",
    "        # Note that grad_hv * grad_vx = sigmoid(x)\n",
    "        #grad_hv = 1./v  \n",
    "        #grad_vx = i.exp()\n",
    "        \n",
    "        grad_hx = i.sigmoid()\n",
    "\n",
    "        grad_gx = grad_gh *  grad_hx #grad_hv * grad_vx \n",
    "        \n",
    "        grad_f =  torch.tanh(F.softplus(i)) + i * grad_gx \n",
    "        \n",
    "        return grad_output * grad_f \n",
    "\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        print(\"Mish initialized\")\n",
    "        pass\n",
    "    def forward(self, input_tensor):\n",
    "        return Mish_func.apply(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "upset-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_activations(model, existing_layer, new_layer): \n",
    "    for name, module in reversed(model._modules.items()):\n",
    "        if len(list(module.children())) > 0:\n",
    "            model._modules[name] = replace_activations(module, existing_layer, new_layer)\n",
    "\n",
    "        if type(module) == existing_layer:\n",
    "            layer_old = module\n",
    "            layer_new = new_layer\n",
    "            model._modules[name] = layer_new\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-brook",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "coastal-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, scale=30.0, margin=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(margin)\n",
    "        self.sin_m = math.sin(margin)\n",
    "        self.th = math.cos(math.pi - margin)\n",
    "        self.mm = math.sin(math.pi - margin) * margin\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.scale\n",
    "\n",
    "        return output, nn.CrossEntropyLoss()(output,label)\n",
    "\n",
    "class ShopeeModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes = Config.CLASSES,\n",
    "        model_name = Config.MODEL_NAME,\n",
    "        fc_dim = Config.FC_DIM,\n",
    "        margin = Config.MARGIN,\n",
    "        scale = Config.SCALE,\n",
    "        use_fc = False, #True,\n",
    "        pretrained = True):\n",
    "\n",
    "\n",
    "        super(ShopeeModel,self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if model_name == 'resnext50_32x4d':\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif 'efficientnet' in model_name:\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "        \n",
    "        elif 'nfnet' in model_name:\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "\n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=0.0)\n",
    "            self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            final_in_features = fc_dim\n",
    "\n",
    "        self.final = ArcMarginProduct(\n",
    "            final_in_features,\n",
    "            n_classes,\n",
    "            scale = scale,\n",
    "            margin = margin,\n",
    "            easy_margin = False,\n",
    "            ls_eps = 0.0\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        feature = self.extract_feat(image)\n",
    "        logits = self.final(feature,label)\n",
    "        return logits\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "detected-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, data_loader, optimizer, scheduler, i):\n",
    "    model.train()\n",
    "    fin_loss = 0.0\n",
    "    tk = tqdm(data_loader, desc = \"Epoch\" + \" [TRAIN] \" + str(i+1))\n",
    "\n",
    "    for t,data in enumerate(tk):\n",
    "        for k,v in data.items():\n",
    "            data[k] = v.to(Config.DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        _, loss = model(**data)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        fin_loss += loss.item() \n",
    "\n",
    "        tk.set_postfix({'loss' : '%.6f' %float(fin_loss/(t+1)), 'LR' : optimizer.param_groups[0]['lr']})\n",
    "        \n",
    "        neptune.log_metric('loss_tr',float(fin_loss/(t+1)))\n",
    "        neptune.log_metric('train_lr',optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    return fin_loss / len(data_loader)\n",
    "\n",
    "# def eval_fn(model, data_loader, i):\n",
    "#     model.eval()\n",
    "#     fin_loss = 0.0\n",
    "#     tk = tqdm(data_loader, desc = \"Epoch\" + \" [VALID] \" + str(i+1))\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for t,data in enumerate(tk):\n",
    "#             for k,v in data.items():\n",
    "#                 data[k] = v.to(Config.DEVICE)\n",
    "#             _, loss = model(**data)\n",
    "#             fin_loss += loss.item() \n",
    "\n",
    "#             tk.set_postfix({'loss' : '%.6f' %float(fin_loss/(t+1))})\n",
    "#         return fin_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "reflected-airport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model Backbone for tf_efficientnet_b5_ns model\n",
      "Mish initialized\n",
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7c5d9b8e434b688d1d12e434a096ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 1:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb56fa22b22b40d3ad21494c9d525fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 2:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef1bed451da42e1974824d0b257895a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 3:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea4fd941c754646955b367a26359993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 4:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f544a727c5142608fbbb49b062ad85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 5:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78eb7c3982b416f88af15b35a1a3fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 6:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfadebff726345f4878f734ad1f6ae1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 7:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616d61a4fcfb420d90626c8e53ba12b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 8:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9795105bbf845d3a0d0507a4c589119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 9:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47db17dec79c4995a444acea67d95e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 10:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2a99ea19b54b4bbe2ea9b73e85c267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 11:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0a3a938bda4c26a36683de4547fda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 12:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac76cd902814dc1bb06d64256651e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 13:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5035127ab34648dba6d615a5c1ac279e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 14:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b13a121cdc4665b51512121efa8ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 15:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a36f7047b63454f87ebcb73a178046e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 16:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464b417c8cc44160925bdd17785624f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 17:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79a7f6aab0249c69921bef040636253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 18:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/urllib3/response.py\", line 697, in _update_chunk_length\n",
      "    self.chunk_left = int(line, 16)\n",
      "ValueError: invalid literal for int() with base 16: b''\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/urllib3/response.py\", line 764, in read_chunked\n",
      "    self._update_chunk_length()\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/urllib3/response.py\", line 701, in _update_chunk_length\n",
      "    raise InvalidChunkLength(self, line)\n",
      "urllib3.exceptions.InvalidChunkLength: InvalidChunkLength(got length b'', 0 bytes read)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/requests/models.py\", line 753, in generate\n",
      "    for chunk in self.raw.stream(chunk_size, decode_content=True):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/urllib3/response.py\", line 572, in stream\n",
      "    for line in self.read_chunked(amt, decode_content=decode_content):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/urllib3/response.py\", line 793, in read_chunked\n",
      "    self._original_response.close()\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/urllib3/response.py\", line 455, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "urllib3.exceptions.ProtocolError: (\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 382, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 197, in response\n",
      "    incoming_response = self._get_incoming_response(timeout)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/requests_client.py\", line 270, in result\n",
      "    **settings\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/requests/sessions.py\", line 697, in send\n",
      "    r.content\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/requests/models.py\", line 831, in content\n",
      "    self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/requests/models.py\", line 756, in generate\n",
      "    raise ChunkedEncodingError(e)\n",
      "requests.exceptions.ChunkedEncodingError: (\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n",
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 382, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 200, in response\n",
      "    swagger_result = self._get_swagger_result(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 303, in _get_swagger_result\n",
      "    self.request_config.response_callbacks,\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 334, in unmarshal_response\n",
      "    raise_on_unexpected(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 408, in raise_on_unexpected\n",
      "    raise make_http_exception(response=http_response)\n",
      "bravado.exception.HTTPServiceUnavailable: 503 Service Temporarily Unavailable: <html>\n",
      "<head><title>503 Service Temporarily Unavailable</title></head>\n",
      "<body>\n",
      "<center><h1>503 Service Temporarily Unavailable</h1></center>\n",
      "<hr><center>nginx</center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 382, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 200, in response\n",
      "    swagger_result = self._get_swagger_result(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 303, in _get_swagger_result\n",
      "    self.request_config.response_callbacks,\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 334, in unmarshal_response\n",
      "    raise_on_unexpected(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 408, in raise_on_unexpected\n",
      "    raise make_http_exception(response=http_response)\n",
      "bravado.exception.HTTPServiceUnavailable: 503 Service Temporarily Unavailable: <html>\n",
      "<head><title>503 Service Temporarily Unavailable</title></head>\n",
      "<body>\n",
      "<center><h1>503 Service Temporarily Unavailable</h1></center>\n",
      "<hr><center>nginx</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75eec3ce8b044ab38166793da530d975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 19:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 382, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 200, in response\n",
      "    swagger_result = self._get_swagger_result(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 303, in _get_swagger_result\n",
      "    self.request_config.response_callbacks,\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 334, in unmarshal_response\n",
      "    raise_on_unexpected(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 408, in raise_on_unexpected\n",
      "    raise make_http_exception(response=http_response)\n",
      "bravado.exception.HTTPServiceUnavailable: 503 Service Temporarily Unavailable: <html>\n",
      "<head><title>503 Service Temporarily Unavailable</title></head>\n",
      "<body>\n",
      "<center><h1>503 Service Temporarily Unavailable</h1></center>\n",
      "<hr><center>nginx</center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 382, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 200, in response\n",
      "    swagger_result = self._get_swagger_result(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 303, in _get_swagger_result\n",
      "    self.request_config.response_callbacks,\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 334, in unmarshal_response\n",
      "    raise_on_unexpected(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 408, in raise_on_unexpected\n",
      "    raise make_http_exception(response=http_response)\n",
      "bravado.exception.HTTPServiceUnavailable: 503 Service Temporarily Unavailable: <html>\n",
      "<head><title>503 Service Temporarily Unavailable</title></head>\n",
      "<body>\n",
      "<center><h1>503 Service Temporarily Unavailable</h1></center>\n",
      "<hr><center>nginx</center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 382, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 200, in response\n",
      "    swagger_result = self._get_swagger_result(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 303, in _get_swagger_result\n",
      "    self.request_config.response_callbacks,\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 334, in unmarshal_response\n",
      "    raise_on_unexpected(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 408, in raise_on_unexpected\n",
      "    raise make_http_exception(response=http_response)\n",
      "bravado.exception.HTTPServiceUnavailable: 503 Service Temporarily Unavailable: <html>\n",
      "<head><title>503 Service Temporarily Unavailable</title></head>\n",
      "<body>\n",
      "<center><h1>503 Service Temporarily Unavailable</h1></center>\n",
      "<hr><center>nginx</center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 382, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 200, in response\n",
      "    swagger_result = self._get_swagger_result(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 303, in _get_swagger_result\n",
      "    self.request_config.response_callbacks,\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 334, in unmarshal_response\n",
      "    raise_on_unexpected(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 408, in raise_on_unexpected\n",
      "    raise make_http_exception(response=http_response)\n",
      "bravado.exception.HTTPServiceUnavailable: 503 Service Temporarily Unavailable: <html>\n",
      "<head><title>503 Service Temporarily Unavailable</title></head>\n",
      "<body>\n",
      "<center><h1>503 Service Temporarily Unavailable</h1></center>\n",
      "<hr><center>nginx</center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 382, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 200, in response\n",
      "    swagger_result = self._get_swagger_result(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 303, in _get_swagger_result\n",
      "    self.request_config.response_callbacks,\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 334, in unmarshal_response\n",
      "    raise_on_unexpected(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 408, in raise_on_unexpected\n",
      "    raise make_http_exception(response=http_response)\n",
      "bravado.exception.HTTPServiceUnavailable: 503 Service Temporarily Unavailable: <html>\n",
      "<head><title>503 Service Temporarily Unavailable</title></head>\n",
      "<body>\n",
      "<center><h1>503 Service Temporarily Unavailable</h1></center>\n",
      "<hr><center>nginx</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 382, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 200, in response\n",
      "    swagger_result = self._get_swagger_result(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 303, in _get_swagger_result\n",
      "    self.request_config.response_callbacks,\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 334, in unmarshal_response\n",
      "    raise_on_unexpected(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 408, in raise_on_unexpected\n",
      "    raise make_http_exception(response=http_response)\n",
      "bravado.exception.HTTPServiceUnavailable: 503 Service Temporarily Unavailable: <html>\n",
      "<head><title>503 Service Temporarily Unavailable</title></head>\n",
      "<body>\n",
      "<center><h1>503 Service Temporarily Unavailable</h1></center>\n",
      "<hr><center>nginx</center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 382, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 200, in response\n",
      "    swagger_result = self._get_swagger_result(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 303, in _get_swagger_result\n",
      "    self.request_config.response_callbacks,\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 334, in unmarshal_response\n",
      "    raise_on_unexpected(incoming_response)\n",
      "  File \"/home/user/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/bravado/http_future.py\", line 408, in raise_on_unexpected\n",
      "    raise make_http_exception(response=http_response)\n",
      "bravado.exception.HTTPServiceUnavailable: 503 Service Temporarily Unavailable: <html>\n",
      "<head><title>503 Service Temporarily Unavailable</title></head>\n",
      "<body>\n",
      "<center><h1>503 Service Temporarily Unavailable</h1></center>\n",
      "<hr><center>nginx</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767ecf0417b849f09dd5c7e73bcd53e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 20:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f49ad02293429aa5604c5c36cee8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 21:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15edfbc64a6247b0a10162e2155e79bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 22:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9daac2a6fe0a40b2b55e3e5a6fe0577c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 23:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7d0110928f4b60b1c415783a76775f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 24:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba6cd33660e49a39c1cc939b677eb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 25:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5765f9b2b09e4320bc6e7ea47cff097c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 26:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf814152fe546b88c94b268ce37faa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 27:   0%|          | 0/4281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7d7c57981c0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{save_dir}/arcface_512x512_efficientnet_B5_ns(mish)_{i}EpochStep.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-7d7c57981c0b>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mavg_loss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{save_dir}/arcface_512x512_efficientnet_B5_ns(mish)_{i}EpochStep.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-0efa55d5d17b>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(model, data_loader, optimizer, scheduler, i)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mfin_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rapids-0.18/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-0dad90ed77c7>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;31m#    grad.add_(-grad.mean(dim=tuple(range(1, grad.dim())), keepdim=True))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc_loc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcentralized_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_conv_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc_conv_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-0dad90ed77c7>\u001b[0m in \u001b[0;36mcentralized_gradient\u001b[0;34m(x, use_gc, gc_conv_only)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_training():\n",
    "    \n",
    "    df = pd.read_csv(Config.TRAIN_CSV)\n",
    "\n",
    "    labelencoder= LabelEncoder()\n",
    "    df['label_group'] = labelencoder.fit_transform(df['label_group'])\n",
    "    \n",
    "    trainset = ShopeeDataset(df, transform = get_train_transforms())\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset,\n",
    "        batch_size = Config.BATCH_SIZE,\n",
    "        pin_memory = True,\n",
    "        num_workers = Config.NUM_WORKERS,\n",
    "        shuffle = True,\n",
    "        drop_last = True\n",
    "    )\n",
    "\n",
    "    model = ShopeeModel()\n",
    "    model.to(Config.DEVICE)\n",
    "    \n",
    "    \n",
    "    existing_layer = torch.nn.SiLU\n",
    "    new_layer = Mish()\n",
    "    model = replace_activations(model, existing_layer, new_layer) # in eca_nfnet_l0 SiLU() is used, but it will be replace by Mish()\n",
    "    \n",
    "    optimizer = Ranger(model.parameters(), lr = Config.SCHEDULER_PARAMS['lr_start'])\n",
    "    scheduler = ShopeeScheduler(optimizer,**Config.SCHEDULER_PARAMS)\n",
    "    \n",
    "    save_dir = f'./Arcface_{Config.MODEL_NAME}_{Config.EPOCHS}_Weights'\n",
    "    if os.path.exists(save_dir) == False :\n",
    "        print('Making Weights Folder')\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    for i in range(Config.EPOCHS):\n",
    "        avg_loss_train = train_fn(model, trainloader, optimizer, scheduler, i)\n",
    "        torch.save(model.state_dict(),f'{save_dir}/arcface_512x512_efficientnet_B5_ns(mish)_{i}EpochStep.pt')\n",
    "\n",
    "run_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
